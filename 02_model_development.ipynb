{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains model development code. I have used only 2 out of 5 tsv files to develop the solution in interest of time. My attempt while solving this assignment is to show the breadth of my knowledge and not necessarily build the best model. The current state of model development process is highly empirical and generally model development process takes multiple iterations to arrive at a solution. The general workflow in the notebook is as follows: \n",
    "\n",
    "\n",
    "1. Data Preprocessing/Feature Engineering/Data Cleaning\n",
    "    * Processed/Filtered invalid/null values\n",
    "    * Removed special characters \n",
    "\n",
    "* Feature Engineering\n",
    "    \n",
    "* Model Selection\n",
    "    * Linear Regression\n",
    "    * Decision Tree\n",
    "    * Random Forest\n",
    "    * XGBoost\n",
    "    \n",
    "* Model Evaluation \n",
    "    * MSE\n",
    "    * RMSE\n",
    "    * MAE\n",
    "    \n",
    "* Hyperparameter Tuning\n",
    "\n",
    "To choose the best solution, I will follow following strategy:\n",
    "\n",
    "- I will iterate multiple times through EDA, Data Preprocessing, Feature Engineering and Data Cleaning (in general it takes approx 70-80% of the time) to find optimal steps. \n",
    "- Assuming no other business metric dictates, I will evaluate multiple models on metrics like RMSE and MAE.\n",
    "- Time to run the algorithm and other production related constraints also play important role in choosing the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state for reproducing the results later\n",
    "RANDOM_STATE=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 2.14 s, total: 16.4 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ratings=pd.read_csv(\"title.ratings.tsv\", sep=\"\\t\")\n",
    "title_basics=pd.read_csv(\"title.basics.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>6.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes\n",
       "0  tt0000001            5.7      1846\n",
       "1  tt0000002            6.0       239\n",
       "2  tt0000003            6.5      1612\n",
       "3  tt0000004            6.0       155\n",
       "4  tt0000005            6.2      2435"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "  isAdult startYear endYear runtimeMinutes                    genres  \n",
       "0       0      1894      \\N              1         Documentary,Short  \n",
       "1       0      1892      \\N              5           Animation,Short  \n",
       "2       0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "3       0      1892      \\N             12           Animation,Short  \n",
       "4       0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.46 s, sys: 1.31 s, total: 9.78 s\n",
      "Wall time: 9.78 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1846</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1612</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>6.0</td>\n",
       "      <td>155</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2435</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes titleType            primaryTitle  \\\n",
       "0  tt0000001            5.7      1846     short              Carmencita   \n",
       "1  tt0000002            6.0       239     short  Le clown et ses chiens   \n",
       "2  tt0000003            6.5      1612     short          Pauvre Pierrot   \n",
       "3  tt0000004            6.0       155     short             Un bon bock   \n",
       "4  tt0000005            6.2      2435     short        Blacksmith Scene   \n",
       "\n",
       "            originalTitle isAdult startYear endYear runtimeMinutes  \\\n",
       "0              Carmencita       0      1894      \\N              1   \n",
       "1  Le clown et ses chiens       0      1892      \\N              5   \n",
       "2          Pauvre Pierrot       0      1892      \\N              4   \n",
       "3             Un bon bock       0      1892      \\N             12   \n",
       "4        Blacksmith Scene       0      1893      \\N              1   \n",
       "\n",
       "                     genres  \n",
       "0         Documentary,Short  \n",
       "1           Animation,Short  \n",
       "2  Animation,Comedy,Romance  \n",
       "3           Animation,Short  \n",
       "4              Comedy,Short  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ratings_combined=ratings.merge(title_basics, on=\"tconst\", how=\"inner\")\n",
    "ratings_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the shape of data after merge\n",
    "assert ratings.shape[0]==ratings_combined.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "ratings_combined.columns=['tconst', 'average_rating', 'num_votes', 'title_type', \n",
    "                                'primary_title', 'original_title', 'is_adult', 'start_year', \n",
    "                                'end_year', 'runtime_minutes', 'genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_movie=ratings_combined[ratings_combined.title_type==\"movie\"]\n",
    "ratings_movie.drop([\"end_year\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "ratings_movie.replace({\"\\\\N\":np.nan}, inplace=True)\n",
    "ratings_movie.replace({None:np.nan}, inplace=True)\n",
    "ratings_movie[\"is_adult\"]=ratings_movie[\"is_adult\"].astype(float).astype(str)\n",
    "numeric_features=[\"average_rating\", \"num_votes\", \"start_year\", \"runtime_minutes\"]\n",
    "ratings_movie[numeric_features]=ratings_movie[numeric_features].astype(float)\n",
    "\n",
    "ratings_movie=ratings_movie[ratings_movie.num_votes>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering-Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature for years since release\n",
    "current_year = datetime.datetime.now().year\n",
    "ratings_movie[\"years_since_release\"]=current_year-ratings_movie[\"start_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a backup copy of data\n",
    "backup=ratings_movie.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_req_cols=[\"tconst\", \"title_type\", \"original_title\", \"primary_title\", \"start_year\", \"genres\"]\n",
    "ratings_movie_non_req=ratings_movie[non_req_cols]\n",
    "# drop features which won't go into model\n",
    "ratings_movie.drop(non_req_cols, axis=\"columns\", inplace=True)\n",
    "# create numeric and categorical feature list\n",
    "num_features=[\"years_since_release\", \"num_votes\", \"runtime_minutes\"]\n",
    "cat_features=[\"is_adult\"]\n",
    "target=\"average_rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=ratings_movie.drop([target], axis=\"columns\")\n",
    "y=ratings_movie[target]\n",
    "\n",
    "assert ratings_movie.shape[0]==X.shape[0]\n",
    "assert ratings_movie.shape[0]==y.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=RANDOM_STATE) \n",
    "\n",
    "assert X.shape[0]==X_train.shape[0]+X_val.shape[0]+X_test.shape[0]\n",
    "assert y.shape[0]==y_train.shape[0]+y_val.shape[0]+y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common practice to fix the shape of distribution while developing with linear regression models. Most of the times, I choose between one of the following transformations empircally:\n",
    "- Log\n",
    "- Squareroot\n",
    "- Reciprocal\n",
    "- Box-cox\n",
    "\n",
    "Note: Box-cox can be only applied to strictly positive values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "While choosing a model in this situation, I will first create a baseline model using a simpler model like Linear Regression or a Decision Tree and then move to more complex models, if required based on performance against a set of objective metrics and other constraints like runtime and maintainability of the model in production environment. \n",
    "\n",
    "* I will choose one of the following models a baseline:\n",
    "    * Logistic Regression\n",
    "    * Decision Tree\n",
    "    * SVM\n",
    "    * Random Forest\n",
    "    \n",
    "* More Advanced models:\n",
    "    * AdaBoost\n",
    "    * XGBoost\n",
    "    * Word2Vec\n",
    "    * Neural Network with Embedding layers\n",
    "    \n",
    "\n",
    "- I also tend to prefer tree-based models for baseline because they require less preprocessing/cleaning. As they are robust to handle missing values and outliers, so it is quicker to build a prototype using these models.\n",
    "- One rule of thumb for putting any model in production is __simpler models__ are easier to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 1-Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   PowerTransformer())]),\n",
       "                                                  ['years_since_release',\n",
       "                                                   'num_votes',\n",
       "                                                   'runtime_minutes']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['is_adult'])])),\n",
       "                ('linear_reg', LinearRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_pipeline(num_features, cat_features):\n",
    "    numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", PowerTransformer())])\n",
    "    categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, num_features),\n",
    "            (\"cat\", categorical_transformer, cat_features),\n",
    "        ])\n",
    "    return preprocessor\n",
    "preprocessor=build_pipeline(num_features, cat_features)    \n",
    "\n",
    "pipe_linear = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"linear_reg\", LinearRegression())]\n",
    ")\n",
    "pipe_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: validation RMSE: 1.2952682610299573\n",
      "data: validation R-Squared: 0.005674568897768628\n",
      "data: train RMSE: 1.3015973476970262\n",
      "data: train R-Squared: 0.005686135817215221\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, y, dataset_type=\"validation\"):\n",
    "    y_pred=model.predict(X)\n",
    "    rmse=mean_squared_error(y, y_pred)**(0.5)\n",
    "    print(f\"data: {dataset_type} RMSE: {rmse}\")\n",
    "    # R2 score\n",
    "    r2=r2_score(y, y_pred)\n",
    "    print(f\"data: {dataset_type} R-Squared: {r2}\")\n",
    "    return rmse, r2\n",
    "y_val_pred=evaluate(pipe_linear, X_val, y_val, dataset_type=\"validation\")\n",
    "y_train_pred=evaluate(pipe_linear, X_train, y_train, dataset_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_residuals=y_val-y_val_pred\n",
    "plt.scatter(lin_residuals,y_val_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has almost no predictive power right now. The empirical nature of model development process requires us to go back to data and extract or develop new features and iterate multiple times to improve. This step is called Feature Engineering.\n",
    "\n",
    "# Feature Engineering-Iteration 2\n",
    "\n",
    "This part of the job is more art than science and this will provide maximum improvement in the model performance. I will now add one more feature: `Genres` into the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>years_since_release</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>6.1</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>action</td>\n",
       "      <td>adventure</td>\n",
       "      <td>biography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>5.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>3.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>drama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     average_rating  num_votes is_adult  runtime_minutes  years_since_release  \\\n",
       "340             4.5       14.0      0.0            100.0                117.0   \n",
       "374             6.1      743.0      0.0             70.0                116.0   \n",
       "383             5.2       16.0      0.0             90.0                115.0   \n",
       "397             4.5       23.0      0.0              NaN                115.0   \n",
       "405             3.8       24.0      0.0              NaN                114.0   \n",
       "\n",
       "    genre_0    genre_1    genre_2  \n",
       "340     NaN        NaN        NaN  \n",
       "374  action  adventure  biography  \n",
       "383   drama       None       None  \n",
       "397   drama       None       None  \n",
       "405   drama       None       None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_movie=backup.copy()\n",
    "\n",
    "def remove_space(x):\n",
    "    if isinstance(x, str):\n",
    "        return str.lower(x.replace(\" \", \"\"))\n",
    "    else:\n",
    "        return np.nan \n",
    "def process_genre(data):\n",
    "    temp=data.copy()\n",
    "    temp['genres'] = temp['genres'].apply(remove_space)\n",
    "    temp=pd.concat([temp, temp.genres.str.split(\",\", expand=True)], axis=\"columns\")\n",
    "    temp.rename(columns={0:\"genre_0\", 1: \"genre_1\", 2: \"genre_2\"}, inplace=True)\n",
    "    temp.drop([\"genres\"], axis=\"columns\", inplace=True)\n",
    "    return temp\n",
    "\n",
    "ratings_movie=process_genre(ratings_movie)   \n",
    "non_req_cols=[\"tconst\", \"title_type\", \"original_title\", \"primary_title\", \"start_year\"]\n",
    "ratings_movie_non_req=ratings_movie[non_req_cols]\n",
    "ratings_movie.drop(non_req_cols, axis=\"columns\", inplace=True)\n",
    "num_features=[\"years_since_release\", \"num_votes\", \"runtime_minutes\"]\n",
    "cat_features=[\"is_adult\", \"genre_0\", \"genre_1\", \"genre_2\"]\n",
    "target=\"average_rating\"\n",
    "ratings_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: validation RMSE: 1.1561394985256819\n",
      "data: validation R-Squared: 0.20780959658523002\n",
      "data: train RMSE: 1.159858835283928\n",
      "data: train R-Squared: 0.21044851388292163\n"
     ]
    }
   ],
   "source": [
    "X=ratings_movie.drop([target], axis=\"columns\")\n",
    "y=ratings_movie[target]\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=RANDOM_STATE) \n",
    "\n",
    "# create pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features),\n",
    "    ]\n",
    ")\n",
    "pipe_linear = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"linear_reg\", LinearRegression())]\n",
    ")\n",
    "# fit model \n",
    "pipe_linear.fit(X_train, y_train)\n",
    "# evaulate model\n",
    "y_val_pred=evaluate(pipe_linear, X_val, y_val, dataset_type=\"validation\")\n",
    "y_train_pred=evaluate(pipe_linear, X_train, y_train, dataset_type=\"train\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The R-Squared somewhat improved from but there is a lot of scope of improvement. In real world, I would systematically add more features like director, actor, writer, region and language details as well to the model but I will stick to only one feature in interest of time. It would be interesting to experiment with CountVectorizer, Word2Vec or developing an Embedding layer using a standard Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 2-DecisionTree\n",
    "\n",
    "As explained before, the tree-based models can handle outliers and missing values automatically so the pipeline steps for treating them first is not required here. However, in interest of time I will use the same pipeline for all my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: validation RMSE: 1.1868704869022317\n",
      "data: validation R-Squared: 0.16513594889437966\n",
      "data: train RMSE: 1.1909044480738376\n",
      "data: train R-Squared: 0.1676154322913187\n"
     ]
    }
   ],
   "source": [
    "pipe_dt = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"decision_tr\", DecisionTreeRegressor(max_depth=4, random_state=RANDOM_STATE))]\n",
    ")\n",
    "pipe_dt.fit(X_train, y_train)\n",
    "y_val_pred_dt=evaluate(pipe_dt, X_val, y_val, dataset_type=\"validation\")\n",
    "y_train_pred_dt=evaluate(pipe_dt, X_train, y_train, dataset_type=\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 3-Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: validation RMSE: 1.1848407096018967\n",
      "data: validation R-Squared: 0.16798906401072067\n",
      "data: train RMSE: 1.1892742030973331\n",
      "data: train R-Squared: 0.16989279713087146\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"rf\", RandomForestRegressor(max_depth=4, random_state=RANDOM_STATE))]\n",
    ")\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "y_val_pred_rf=evaluate(pipe_rf, X_val, y_val, dataset_type=\"validation\")\n",
    "y_train_pred_rf=evaluate(pipe_rf, X_train, y_train, dataset_type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 4-XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:36:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "data: validation RMSE: 1.0834717592060452\n",
      "data: validation R-Squared: 0.30426429579303604\n",
      "data: train RMSE: 1.0770345393717178\n",
      "data: train R-Squared: 0.3191844808602571\n"
     ]
    }
   ],
   "source": [
    "pipe_xgb = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"xgb\", XGBRegressor(n_estimators=100, max_depth=6, eta=0.1, subsample=0.7, colsample_bytree=0.8, random_state=RANDOM_STATE))]\n",
    ")\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "y_val_pred_xgb=evaluate(pipe_xgb, X_val, y_val, dataset_type=\"validation\")\n",
    "y_train_pred_xgb=evaluate(pipe_xgb, X_train, y_train, dataset_type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization using Randomized Search\n",
    " \n",
    "For the sake of this excercise and demostrating my familiarity with the concept, I will go ahead and use RandomizedSearch for XGBoost model. \n",
    "\n",
    "I generally prefer RandomizedSearch over GridSearch because empirically Randomized Search has proven to converge faster. In recent years, Bayesian hyperparameter search has become very popular and is faster than both above options. Bayesian Hyperparameter Search have some strong open source ([scikit-optimize](https://scikit-optimize.github.io/stable/)) and proprietary solutions like [AWS Sagemaker Hyperparameter Tuning](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) module. I have used AWS SageMaker's bayesian hyperparameter optimization module extensively in my past assignments.\n",
    "\n",
    "* In general, the guiding principle will be __Bias Variance Trade-Off__ which means you turn the knobs between complicated model and simple model using these hyperparameters. We say that a model has a high bias if it is not able to fully use the information in the data. We say that a model has high variance if it is using too much information from the the data. More complexity is associated with higher variance.\n",
    "\n",
    "* In multiple iterations, I would have performed hyperparameter search by making educated guesses in each consecutive iteration following the logic mentioned below.\n",
    "\n",
    "* If model is performing better on training data as compared to test data, we have problem of __Overfitting__ and we can do following with hyperparameters:\n",
    "    * Decrease max_depth\n",
    "    * Decrease num_round\n",
    "    * Increase min_child_weight\n",
    "    * Increase gamma\n",
    "    * Increase alpha (L1 regularization)\n",
    "    * Increase lambda (L2 regularization)\n",
    "    * Decrease colsample_bytree\n",
    "    * Decrease subsample\n",
    "        \n",
    "* If model is performing bad on both training data and test data, we have problem of __Underfitting__ and we can create a more complex model by following the exact opposite direction for hyperparameter values as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following codeblock is running out of memory on my local machine but this can run on a EC2 or any distributed environment with more compute like SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Adding more parameters will give better exploring power but will increase processing time in a combinatorial way\n",
    "params = {'learning_rate' :stats.uniform(0.001,0.2),\n",
    "          'n_estimators':[10,50,100, 500, 1000, 2000],\n",
    "          'gamma':stats.uniform(0,0.02),\n",
    "          'subsample':(0.2,0.3,0.4,0.5,0.6, 0.7, 0.8),\n",
    "          'reg_alpha':[25,50,75,100,150,200],\n",
    "          'reg_lambda':[25,50,75,100,150,200],\n",
    "          'max_depth':np.arange(1,11),\n",
    "          'min_child_weight':np.arange(1,11)}\n",
    "\n",
    "pipe_xgb = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"xgb\", XGBRegressor(random_state=RANDOM_STATE))]\n",
    ")\n",
    "research_cv = RandomizedSearchCV(estimator=pipe_xgb, param_distributions=params, n_iter=15, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "research_cv.fit(X_train, y_train)\n",
    "print(\"Best estimator: \",research_cv.best_estimator_)\n",
    "print(\"Best Cross Validation Score: \",research_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Else?\n",
    "\n",
    "Most of the lift in the model performance is done while iterating through data while preprocessing and cleaning and 5-10% uplift can be observed by using Hyperparameter optimization. \n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "During this take-home assignment, I went through a lot of good online resources some of which I am including here for reference.\n",
    "\n",
    "- Applied Machine Learning [AI for All Humans](https://cloud.google.com/blog/topics/developers-practitioners/ai-all-humans-course-delight-and-inspire?utm_campaign=6166fac5808ba700018472fd&utm_content=61af8d861b2ece00012a28e8&utm_medium=smarpshare&utm_source=linkedin)\n",
    "- Text Extraction [O'Reilly Applied Text Analysis](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html)\n",
    "- Sklearn randomized search cv [Randomized Search CV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- Kaggle Movie Recommendations: [Kaggle Movie Recommendations](https://www.kaggle.com/ibtesama/getting-started-with-a-movie-recommendation-system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
